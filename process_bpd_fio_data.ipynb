{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_api_url(url: str) -> pd.DataFrame:\n",
    "    \"\"\"Convert data.boston.gov's JSON API response into a dataframe.\"\"\"\n",
    "    json = requests.get(url).json()\n",
    "    records = json[\"result\"][\"records\"]\n",
    "    df = pd.DataFrame(records).astype(str)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_url(resource_id: str) -> str:\n",
    "    return f\"https://data.boston.gov/api/3/action/datastore_search?resource_id={resource_id}&limit=100000\"\n",
    "\n",
    "\n",
    "# List table URLs by order of year: 2016, 2017, 2018, 2019\n",
    "contact_urls = [\n",
    "    make_url(\"35f3fb8f-4a01-4242-9758-f664e7ead125\"),\n",
    "    make_url(\"c72b9288-2658-4e6a-9686-ffdcacb585e7\"),\n",
    "    make_url(\"ee4f1175-54b6-4d06-bceb-26d349118e25\"),\n",
    "    make_url(\"35cfa498-cb10-43da-b8b2-948a66e48f26\"),\n",
    "    make_url(\"03f33240-47c1-46f2-87ae-bcdabec092ad\"),\n",
    "]\n",
    "people_urls = [\n",
    "    make_url(\"ebb9c51c-6e9a-40a4-94d0-895de9bf47ad\"),\n",
    "    make_url(\"f18a0632-46ea-4032-9749-f5b50cf7b865\"),\n",
    "    make_url(\"aa46b3ad-1526-4551-9f0f-6dbdfbb429c0\"),\n",
    "    make_url(\"b102d3a4-8b44-443e-bc09-00c44974c3b1\"),\n",
    "    make_url(\"2d29a168-534b-47c4-977a-b8f4aaf2ea8c\"),\n",
    "]\n",
    "\n",
    "# Load, join, and concatenate all dataframes\n",
    "contact_df = pd.concat([df_from_api_url(url) for url in contact_urls], sort=False)\n",
    "people_df = pd.concat([df_from_api_url(url) for url in people_urls], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "df_transforms = []\n",
    "\n",
    "\n",
    "def register_transform(f: callable) -> callable:\n",
    "    df_transforms.append(f)\n",
    "    return f\n",
    "\n",
    "\n",
    "def apply_transforms(\n",
    "    contact_df: pd.DataFrame, people_df: pd.DataFrame\n",
    ") -> (pd.DataFrame, pd.DataFrame):\n",
    "    for t in df_transforms:\n",
    "        contact_df, people_df = t(contact_df, people_df)\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def rename_frisk_columns(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    Combine the `frisked` and `searchperson` columns from the ___contacts___ table into one column called `fc_involved_frisk_or_search`,\n",
    "    and disambiguate it from a related column in the ___people___ table by renaming the `frisk/search` column to `person_frisked_or_searched`.\n",
    "    As noted on data.boston.gov, the `frisked` and `searchperson` columns (from the \"New RMS\" data system) indicate whether any of the \n",
    "    individuals stopped in a given field contact was frisked, whereas `frisk/search` (from the \"Mark43\" data system) indicates whether\n",
    "    a particular person involved in a field contact was frisked.\n",
    "    \"\"\"\n",
    "    combine_fields = (\n",
    "        lambda row: \"Y\"\n",
    "        if row.frisked == \"Y\" or row.searchperson == \"Y\"\n",
    "        else row.frisked\n",
    "    )\n",
    "    combined_values = contact_df[[\"frisked\", \"searchperson\"]].apply(\n",
    "        combine_fields, axis=1\n",
    "    )\n",
    "    contact_df = contact_df.assign(fc_involved_frisk_or_search=combined_values)\n",
    "    contact_df = contact_df.drop(columns=[\"frisked\", \"searchperson\"])\n",
    "\n",
    "    people_df = people_df.rename(columns={\"frisk/search\": \"person_frisked_or_searched\"})\n",
    "    people_df.person_frisked_or_searched = people_df.person_frisked_or_searched.replace(\n",
    "        {\"0\": \"N\", \"1\": \"Y\"}\n",
    "    )\n",
    "\n",
    "    # The newer system doesn't provide contact-level frisk info,\n",
    "    # but we can infer whether a contact involved a frisk/search based on\n",
    "    # whether the people involved in that contact were frisked.\n",
    "    contacts_with_no_data = contact_df.fc_involved_frisk_or_search.isnull()\n",
    "    contact_involved_frisk = people_df.groupby(\"fc_num\").apply(\n",
    "        lambda g: \"Y\"\n",
    "        if (g.person_frisked_or_searched == \"Y\").any()\n",
    "        else \"N\"\n",
    "        if (g.person_frisked_or_searched == \"N\").all()\n",
    "        else np.nan\n",
    "    )\n",
    "    contact_df.loc[contacts_with_no_data, \"fc_involved_frisk_or_search\"] = contact_df[\n",
    "        contacts_with_no_data\n",
    "    ].apply(lambda row: contact_involved_frisk.loc[row.fc_num], axis=1)\n",
    "\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def vehicle_info_cleanup(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    Clean up and reconcile vehicle-related field values from the ___contacts___ table. Across the different data systems, different text values\n",
    "    were used to represent identical or overlapping concepts (e.g. \"LT. BLUE\" and \"light blue\", \"Suv (sport Utility Vehicle)\" \n",
    "    and \"SUV or Utility Van\"). Also, drop the `vehicle_style` column, which is basically a noisier version of the `vehicle_type` column.\n",
    "    \"\"\"\n",
    "    contact_df.vehicle_type = contact_df.vehicle_type.replace(\n",
    "        {\n",
    "            \"Scooter\": \"Motorcycle or Scooter\",\n",
    "            \"Cargo Van\": \"SUV or Utility Van\",\n",
    "            \"Suv (sport Utility Vehicle)\": \"SUV or Utility Van\",\n",
    "            \"Passenger Van\": \"Bus or Passenger Van\",\n",
    "            \"Bus/Passenger Van\": \"Bus or Passenger Van\",\n",
    "            \"Passenger Car/ Automobile\": \"Passenger Car\",\n",
    "        }\n",
    "    )\n",
    "    contact_df.vehicle_color = (\n",
    "        contact_df.vehicle_color.str.lower()\n",
    "        .str.strip()\n",
    "        .replace(\n",
    "            {\n",
    "                \"bla\": \"black\",\n",
    "                \"gra\": \"gray\",\n",
    "                \"gre\": \"green\",\n",
    "                \"lt. green\": \"light green\",\n",
    "                \"lt. blue\": \"light blue\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def fix_year(year: str) -> str:\n",
    "        if not year or year in (\"None\", \"NULL\"):\n",
    "            return year\n",
    "        num_year = float(year)\n",
    "        if np.isnan(num_year):\n",
    "            return year\n",
    "        if num_year > 1900:\n",
    "            return year\n",
    "        if num_year > 99:\n",
    "            # Exclude definite typos\n",
    "            return \"NULL\"\n",
    "        if num_year < 10:\n",
    "            return f\"200{year}\"\n",
    "        if num_year < 21:\n",
    "            return f\"20{year}\"\n",
    "        else:\n",
    "            return f\"19{year}\"\n",
    "\n",
    "    contact_df.vehicle_year = contact_df.vehicle_year.apply(fix_year)\n",
    "\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def contact_date_to_dt(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    Convert the `contact_date` column in the ___contacts___ table to datetime, \n",
    "    and drop a duplicate column from the ___people___ table.\n",
    "    \"\"\"\n",
    "    contact_df.contact_date = pd.to_datetime(contact_df.contact_date)\n",
    "\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def clean_officer_and_supervisor_names(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    Remove extra whitespace from the `contact_officer_name` column in the ___contacts___ table \n",
    "    to reduce accidental duplication. Also, put officer's first names first.\n",
    "    \"\"\"\n",
    "    observed_names = {}\n",
    "\n",
    "    def clean_name(id: str, name: str) -> str:\n",
    "        if id in observed_names:\n",
    "            return observed_names[id]\n",
    "\n",
    "        name = name.replace(\".\", \"\")\n",
    "        split_name = [part.strip() for part in name.split(\",\")]\n",
    "        clean_name = None\n",
    "        if len(split_name) == 1:\n",
    "            clean_name = split_name[0]\n",
    "        elif len(split_name) <= 3:\n",
    "            last_part, *first_part = split_name\n",
    "            clean_name = f'{\" \".join(first_part)} {last_part}'\n",
    "\n",
    "        if not clean_name:\n",
    "            raise Exception(f\"Encountered name with unexpected structure: {name}\")\n",
    "\n",
    "        clean_name = clean_name.upper()\n",
    "        observed_names[id] = clean_name\n",
    "        return clean_name\n",
    "\n",
    "    contact_df.supervisor_name = contact_df.apply(\n",
    "        lambda row: clean_name(row.supervisor, row.supervisor_name), axis=1\n",
    "    )\n",
    "    contact_df.contact_officer_name = contact_df.apply(\n",
    "        lambda row: clean_name(row.contact_officer, row.contact_officer_name), axis=1\n",
    "    )\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def combine_contact_reason_and_narrative(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    Merge the ___contacts___ table's `contact_reason` column into the `narrative` column. `contact_reason` serves the same purpose as `narrative`,\n",
    "    just for the older system. Uppercase both columns for consistency.\n",
    "    \"\"\"\n",
    "    empty_narrative = contact_df.narrative.isnull()\n",
    "    contact_df.loc[empty_narrative, \"narrative\"] = contact_df[\n",
    "        empty_narrative\n",
    "    ].contact_reason\n",
    "    contact_df.narrative = contact_df.narrative.str.upper()\n",
    "    contact_df = contact_df.drop(columns=[\"contact_reason\"])\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def clean_up_city(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    There are lots of typos and inconsistencies in the ___contacts___ table's `city` column, so fix them.\n",
    "    Warning: current solution is not robust to *new* typos, should the data change.\n",
    "    \"\"\"\n",
    "    BOSTON = \"BOSTON\"\n",
    "    SOUTHIE = \"SOUTH BOSTON\"\n",
    "    DORCHESTER = \"DORCHESTER\"\n",
    "    CHARLESTOWN = \"CHARLESTOWN\"\n",
    "    JP = \"JAMAICA PLAIN\"\n",
    "    EASTIE = \"EAST BOSTON\"\n",
    "    MATTAPAN = \"MATTAPAN\"\n",
    "    ROXBURY = \"ROXBURY\"\n",
    "    HYDEPARK = \"HYDE PARK\"\n",
    "    contact_df.city = contact_df.city.str.upper()\n",
    "    contact_df.city = contact_df.city.replace(\n",
    "        {\n",
    "            \"BSTN\": BOSTON,\n",
    "            \"SO.BOSTON\": SOUTHIE,\n",
    "            \"DORCCHESTER\": DORCHESTER,\n",
    "            \"CHAARLESTOWN\": CHARLESTOWN,\n",
    "            \"JP\": JP,\n",
    "            \"EAST BOS\": EASTIE,\n",
    "            \"CHALRESTOWN\": CHARLESTOWN,\n",
    "            \"EAST BOSTN\": EASTIE,\n",
    "            \"DOR\": DORCHESTER,\n",
    "            \"MT\": MATTAPAN,\n",
    "            \"S BOSTON\": SOUTHIE,\n",
    "            \"DORCHSTER\": DORCHESTER,\n",
    "            \"BST\": BOSTON,\n",
    "            \"S BSTN\": SOUTHIE,\n",
    "            \"DORCHESTERR\": DORCHESTER,\n",
    "            \"JAMAIICA PLAIN\": JP,\n",
    "            \"ROXBURY MA\": ROXBURY,\n",
    "            \"SO BOSTON\": SOUTHIE,\n",
    "            \"E. BOSTON\": EASTIE,\n",
    "            \"JAMAICA\": JP,\n",
    "            \"DDORCHESTER\": DORCHESTER,\n",
    "            \"MATTPAN\": MATTAPAN,\n",
    "            \"JAMAICIA\": JP,\n",
    "            \"S. BOSTON\": SOUTHIE,\n",
    "            \"HP\": HYDEPARK,\n",
    "            \"DORCHEST\": DORCHESTER,\n",
    "            \"SBOS\": SOUTHIE,\n",
    "            \"ROX\": ROXBURY,\n",
    "            \"CHARLESTWON\": CHARLESTOWN,\n",
    "            \"JAMACIA PLAIN\": JP,\n",
    "            \"ROBURY\": ROXBURY,\n",
    "            \"BTSN\": BOSTON,\n",
    "            \"SOMMERVILLE\": \"SOMERVILLE\",\n",
    "            \"JAMAICIA PLAIN\": JP,\n",
    "            \"S.BOSTON\": SOUTHIE,\n",
    "            \"DOR.\": DORCHESTER,\n",
    "            \"E BOSTON\": EASTIE,\n",
    "            \"E.BOSTON\": EASTIE,\n",
    "            \"BOSTOB\": BOSTON,\n",
    "            \"ROSLINDLAE\": \"ROSLINDALE\",\n",
    "            \"BSNT\": BOSTON,\n",
    "            \"BSTNA\": BOSTON,\n",
    "            \"BSTON\": BOSTON,\n",
    "            \"JAMAIACA PLAIN\": JP,\n",
    "            \"SO. BOSTON\": SOUTHIE,\n",
    "        }\n",
    "    )\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def clean_up_age(contact_df, people_df):\n",
    "    \"\"\"Remove implausibly high values in the ___people___ table's `age` column. Also, convert string values to float.\"\"\"\n",
    "    people_df.age = people_df.age.apply(\n",
    "        lambda age: np.nan if len(age) > 2 or age == \"\" else np.float(age)\n",
    "    )\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def combine_skin_tone_and_complexion(contact_df, people_df):\n",
    "    \"\"\"Merge the ___people___ table's older `complexion` column into the newer `skin_tone` column.\"\"\"\n",
    "    empty_skin_tone = people_df.skin_tone.isnull()\n",
    "    people_df.loc[empty_skin_tone, \"skin_tone\"] = people_df.complexion[empty_skin_tone]\n",
    "    people_df.skin_tone = people_df.skin_tone.replace({\"OTHER\": \"Other\"})\n",
    "    people_df = people_df.drop(columns=[\"complexion\"])\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def drop_deceased_column(contact_df, people_df):\n",
    "    \"\"\"\n",
    "    Drop the `deceased` column from the ___people___ table, since it doesn't exist in the older system, and since no one \n",
    "    is marked deceased in this dataset.\n",
    "    \"\"\"\n",
    "    people_df = people_df.drop(columns=[\"deceased\"])\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def reconcile_hair_style(contact_df, people_df):\n",
    "    \"\"\"Reconcile the ___people___ table's `hair_style` values that seem to mean the same thing.\"\"\"\n",
    "    people_df.hair_style = people_df.hair_style.replace(\n",
    "        {\n",
    "            \"Receding / Thin\": \"Receding or Thin\",\n",
    "            \"Receding or Slightly Receding\": \"Receding or Thin\",\n",
    "            \"Bald\": \"Bald or Balding\",\n",
    "            \"Braids\": \"Braided\",\n",
    "            \"Wig/hair Piece\": \"Wig or Hair Piece\",\n",
    "        }\n",
    "    )\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def reconcile_race(contact_df, people_df):\n",
    "    \"\"\"Reconcile ___people___ table `race` values that seem to mean the same thing.\"\"\"\n",
    "    people_df.race = people_df.race.replace(\n",
    "        {\"American Indian or Alaskan Native\": \"Native American / Alaskan Native\"}\n",
    "    )\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def clean_up_state(contact_df, people_df):\n",
    "    \"\"\"Fix recurrent typo in the ___contacts___ table `state` column.\"\"\"\n",
    "    contact_df.state = contact_df.state.replace({\"MX\": \"MA\"})\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def reconcile_stop_duration(contact_df, people_df):\n",
    "    \"\"\"Bucket ___contacts___ table `stop_duration` column values listed as minutes and remove likely typos.\"\"\"\n",
    "\n",
    "    def bucket_stop_duration(d: str) -> str:\n",
    "        try:\n",
    "            d = int(d)\n",
    "        except:\n",
    "            return d\n",
    "\n",
    "        # A stop longer than 8 hours seems really implausible\n",
    "        if d > 500:\n",
    "            return \"NULL\"\n",
    "        if d < 5:\n",
    "            return \"Less Than Five Minutes\"\n",
    "        if d < 10:\n",
    "            return \"Five to Ten Minutes\"\n",
    "        if d < 15:\n",
    "            return \"Ten to Fifteen Minutes\"\n",
    "        if d < 20:\n",
    "            return \"Fifteen to Twenty Minutes\"\n",
    "        if d < 25:\n",
    "            return \"Twenty to Twenty-Five Minutes\"\n",
    "        if d < 30:\n",
    "            return \"Twenty-Five to Thirty Minutes\"\n",
    "        if d < 45:\n",
    "            return \"Thirty to Forty-Five Minutes\"\n",
    "        if d < 60:\n",
    "            return \"Forty-Five to Sixty Minutes\"\n",
    "        if d < 120:\n",
    "            return \"One to Two Hours\"\n",
    "        return \"Longer Than Two Hours\"\n",
    "\n",
    "    contact_df.stop_duration = contact_df.stop_duration.apply(bucket_stop_duration)\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def clean_location_info(contact_df, people_df):\n",
    "    \"\"\"Combine the ___contacts___ table's `street` and `streetaddr` columns into single `street` column, and trim extra digits from `zip`.\"\"\"\n",
    "    empty_street = contact_df.street.isnull()\n",
    "    contact_df.loc[empty_street, \"street\"] = contact_df.streetaddr[empty_street]\n",
    "    contact_df.street = contact_df.street.apply(lambda s: s.replace(\"&\", \"/\"))\n",
    "    contact_df.zip = contact_df.zip.apply(lambda zip: zip.split(\"-\")[0])\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "@register_transform\n",
    "def clean_empty_values(contact_df, people_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    The values `''`, `'NULL'`, and `'None'` are used to signify no value was entered in various fields across the dataset.\n",
    "    Replace these values with `np.nan`.\n",
    "    \"\"\"\n",
    "    replacements = {\"\": np.nan, \"NULL\": np.nan, \"None\": np.nan}\n",
    "    contact_df = contact_df.replace(replacements)\n",
    "    people_df = people_df.replace(replacements)\n",
    "    return contact_df, people_df\n",
    "\n",
    "\n",
    "clean_contact_df, clean__people__df = apply_transforms(contact_df, people_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the cleaned data as CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_contact_df.to_csv(\"foi_contacts.csv\", index=False)\n",
    "clean__people__df.to_csv(\"foi_people.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-populate the README with changes applied to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_changelist = \"\\n\".join([f\"- {f.__doc__.strip()}\" for f in df_transforms])\n",
    "\n",
    "with open(\"README.md\", \"r\") as readme:\n",
    "    readme_body = readme.read()\n",
    "    readme_trunc_body, _ = readme_body.split(\"## Data-cleaning operations\")\n",
    "\n",
    "with open(\"README.md\", \"w\") as readme:\n",
    "    readme.write(\n",
    "        f\"{readme_trunc_body}\\n## Data-cleaning operations\\n{readme_changelist}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}